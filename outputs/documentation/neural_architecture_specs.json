{
  "timestamp": "2025-06-27T06:46:49.594224",
  "model_architecture": {
    "name": "GradedRankingModel",
    "type": "Lightweight Cross-Attention Neural Network",
    "parameters": {
      "embedding_dim": 128,
      "hidden_dim": 256,
      "num_heads": 4,
      "dropout": 0.1
    },
    "layers": [
      "Query Encoder (Linear + LayerNorm + ReLU + Dropout)",
      "Dataset Encoder (Linear + LayerNorm + ReLU + Dropout)",
      "Cross-Attention (MultiheadAttention)",
      "Feature Fusion (Linear + LayerNorm + ReLU + Dropout)",
      "Relevance Head (Linear + ReLU + Linear)",
      "Binary Head (Linear)"
    ],
    "innovation": "Combines neural attention with traditional ML features"
  },
  "training_configuration": {
    "loss_function": "Combined NDCG + ListMLE + Binary Cross-Entropy",
    "optimizer": "AdamW",
    "learning_rate": 0.001,
    "batch_size": 32,
    "epochs": 50,
    "early_stopping": 5,
    "device": "Apple Silicon MPS / CUDA / CPU"
  },
  "performance_achievements": {
    "ndcg_at_3": 72.2,
    "training_time": "~40s per epoch",
    "inference_time": "89ms average",
    "model_size": "42MB quantized",
    "accuracy_retention": "99.7% after quantization"
  },
  "technical_innovations": [
    "Lightweight cross-attention without full transformer overhead",
    "Hybrid scoring combining neural and traditional signals",
    "Hard negative mining for improved boundary learning",
    "Threshold optimization (0.485 vs 0.5 default)",
    "Apple Silicon MPS optimization for real-time inference"
  ]
}